{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, recall_score, precision_score, f1_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-Statistic algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    '/Users/scottlichtenstein/Desktop/IE/Term 3/Capstone/capstone.airbus/Notebooks/generated_data/merged_dataset_with_fuel_leak.csv'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    247436\n",
       "1     61912\n",
       "2     61610\n",
       "3     61290\n",
       "Name: leakage, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.leakage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UTC_TIME</th>\n",
       "      <th>MSN</th>\n",
       "      <th>Flight</th>\n",
       "      <th>FUEL_USED_1</th>\n",
       "      <th>FUEL_USED_2</th>\n",
       "      <th>FUEL_USED_3</th>\n",
       "      <th>FUEL_USED_4</th>\n",
       "      <th>FW_GEO_ALTITUDE</th>\n",
       "      <th>VALUE_FOB</th>\n",
       "      <th>VALUE_FUEL_QTY_CT</th>\n",
       "      <th>...</th>\n",
       "      <th>leakage</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>FLIGHT</th>\n",
       "      <th>TOTAL_FUEL_USED</th>\n",
       "      <th>VALUE_FOB_DIFF</th>\n",
       "      <th>TOTAL_FOB_BY_QTY</th>\n",
       "      <th>DELTA_VFOB_VS_VFOBQTY</th>\n",
       "      <th>ALTITUDE_DIFF</th>\n",
       "      <th>VALUE_FOB_MISSING</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-07 07:40:16</td>\n",
       "      <td>A400M-0002</td>\n",
       "      <td>V0926</td>\n",
       "      <td>18.685520</td>\n",
       "      <td>14.602920</td>\n",
       "      <td>11.800570</td>\n",
       "      <td>8.456606</td>\n",
       "      <td>539.7343</td>\n",
       "      <td>17862.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>07:40:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.545616</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>17864.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-07 07:40:17</td>\n",
       "      <td>A400M-0002</td>\n",
       "      <td>V0926</td>\n",
       "      <td>18.790150</td>\n",
       "      <td>14.708280</td>\n",
       "      <td>11.915550</td>\n",
       "      <td>8.561913</td>\n",
       "      <td>539.7372</td>\n",
       "      <td>17862.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>07:40:17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.975893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17864.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-07 07:40:18</td>\n",
       "      <td>A400M-0002</td>\n",
       "      <td>V0926</td>\n",
       "      <td>18.894430</td>\n",
       "      <td>14.812860</td>\n",
       "      <td>12.021070</td>\n",
       "      <td>8.669324</td>\n",
       "      <td>539.7568</td>\n",
       "      <td>17861.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>07:40:18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.397684</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>17864.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-07 07:40:19</td>\n",
       "      <td>A400M-0002</td>\n",
       "      <td>V0926</td>\n",
       "      <td>18.999000</td>\n",
       "      <td>14.917660</td>\n",
       "      <td>12.126170</td>\n",
       "      <td>8.777307</td>\n",
       "      <td>539.2781</td>\n",
       "      <td>17861.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>07:40:19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.820137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17863.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.4787</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-07 07:40:20</td>\n",
       "      <td>A400M-0002</td>\n",
       "      <td>V0926</td>\n",
       "      <td>19.103010</td>\n",
       "      <td>15.022960</td>\n",
       "      <td>12.231340</td>\n",
       "      <td>8.885483</td>\n",
       "      <td>539.2698</td>\n",
       "      <td>17858.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>07:40:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.242793</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>17862.000000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432243</th>\n",
       "      <td>2018-03-21 00:27:12</td>\n",
       "      <td>F-RBAJ</td>\n",
       "      <td>453.0</td>\n",
       "      <td>642.875916</td>\n",
       "      <td>646.364136</td>\n",
       "      <td>652.033813</td>\n",
       "      <td>646.515503</td>\n",
       "      <td>26496.0000</td>\n",
       "      <td>15076.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>00:27:12</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2587.789368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15078.916667</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432244</th>\n",
       "      <td>2018-03-21 00:27:13</td>\n",
       "      <td>F-RBAJ</td>\n",
       "      <td>453.0</td>\n",
       "      <td>643.186523</td>\n",
       "      <td>646.633911</td>\n",
       "      <td>652.346375</td>\n",
       "      <td>646.869507</td>\n",
       "      <td>26496.0000</td>\n",
       "      <td>15076.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>00:27:13</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2589.036316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15078.916667</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432245</th>\n",
       "      <td>2018-03-21 00:27:14</td>\n",
       "      <td>F-RBAJ</td>\n",
       "      <td>453.0</td>\n",
       "      <td>643.535217</td>\n",
       "      <td>646.980530</td>\n",
       "      <td>652.698486</td>\n",
       "      <td>647.183655</td>\n",
       "      <td>26494.0000</td>\n",
       "      <td>15075.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>00:27:14</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2590.397888</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>15078.916667</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432246</th>\n",
       "      <td>2018-03-21 00:27:15</td>\n",
       "      <td>F-RBAJ</td>\n",
       "      <td>453.0</td>\n",
       "      <td>643.844299</td>\n",
       "      <td>647.289856</td>\n",
       "      <td>652.972717</td>\n",
       "      <td>647.497803</td>\n",
       "      <td>26496.0000</td>\n",
       "      <td>15076.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>00:27:15</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2591.604675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15078.916667</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432247</th>\n",
       "      <td>2018-03-21 00:27:20</td>\n",
       "      <td>F-RBAJ</td>\n",
       "      <td>453.0</td>\n",
       "      <td>645.158203</td>\n",
       "      <td>648.590393</td>\n",
       "      <td>654.374817</td>\n",
       "      <td>648.868713</td>\n",
       "      <td>26496.0000</td>\n",
       "      <td>15070.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>00:27:20</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2596.992126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15073.916667</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432248 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   UTC_TIME         MSN Flight  FUEL_USED_1  FUEL_USED_2  \\\n",
       "0       2016-10-07 07:40:16  A400M-0002  V0926    18.685520    14.602920   \n",
       "1       2016-10-07 07:40:17  A400M-0002  V0926    18.790150    14.708280   \n",
       "2       2016-10-07 07:40:18  A400M-0002  V0926    18.894430    14.812860   \n",
       "3       2016-10-07 07:40:19  A400M-0002  V0926    18.999000    14.917660   \n",
       "4       2016-10-07 07:40:20  A400M-0002  V0926    19.103010    15.022960   \n",
       "...                     ...         ...    ...          ...          ...   \n",
       "432243  2018-03-21 00:27:12      F-RBAJ  453.0   642.875916   646.364136   \n",
       "432244  2018-03-21 00:27:13      F-RBAJ  453.0   643.186523   646.633911   \n",
       "432245  2018-03-21 00:27:14      F-RBAJ  453.0   643.535217   646.980530   \n",
       "432246  2018-03-21 00:27:15      F-RBAJ  453.0   643.844299   647.289856   \n",
       "432247  2018-03-21 00:27:20      F-RBAJ  453.0   645.158203   648.590393   \n",
       "\n",
       "        FUEL_USED_3  FUEL_USED_4  FW_GEO_ALTITUDE     VALUE_FOB  \\\n",
       "0         11.800570     8.456606         539.7343  17862.000000   \n",
       "1         11.915550     8.561913         539.7372  17862.000000   \n",
       "2         12.021070     8.669324         539.7568  17861.000000   \n",
       "3         12.126170     8.777307         539.2781  17861.000000   \n",
       "4         12.231340     8.885483         539.2698  17858.000000   \n",
       "...             ...          ...              ...           ...   \n",
       "432243   652.033813   646.515503       26496.0000  15076.916667   \n",
       "432244   652.346375   646.869507       26496.0000  15076.916667   \n",
       "432245   652.698486   647.183655       26494.0000  15075.916667   \n",
       "432246   652.972717   647.497803       26496.0000  15076.916667   \n",
       "432247   654.374817   648.868713       26496.0000  15070.916667   \n",
       "\n",
       "        VALUE_FUEL_QTY_CT  ...  leakage        DATE      TIME  FLIGHT  \\\n",
       "0                     0.0  ...        0  2016-10-07  07:40:16     0.0   \n",
       "1                     0.0  ...        0  2016-10-07  07:40:17     0.0   \n",
       "2                     0.0  ...        0  2016-10-07  07:40:18     0.0   \n",
       "3                     0.0  ...        0  2016-10-07  07:40:19     0.0   \n",
       "4                     0.0  ...        0  2016-10-07  07:40:20     0.0   \n",
       "...                   ...  ...      ...         ...       ...     ...   \n",
       "432243                0.0  ...        1  2018-03-21  00:27:12   980.0   \n",
       "432244                0.0  ...        1  2018-03-21  00:27:13   980.0   \n",
       "432245                0.0  ...        1  2018-03-21  00:27:14   980.0   \n",
       "432246                0.0  ...        1  2018-03-21  00:27:15   980.0   \n",
       "432247                0.0  ...        1  2018-03-21  00:27:20   980.0   \n",
       "\n",
       "        TOTAL_FUEL_USED  VALUE_FOB_DIFF  TOTAL_FOB_BY_QTY  \\\n",
       "0             53.545616            -1.0      17864.000000   \n",
       "1             53.975893             0.0      17864.000000   \n",
       "2             54.397684            -1.0      17864.000000   \n",
       "3             54.820137             0.0      17863.000000   \n",
       "4             55.242793            -3.0      17862.000000   \n",
       "...                 ...             ...               ...   \n",
       "432243      2587.789368             0.0      15078.916667   \n",
       "432244      2589.036316             0.0      15078.916667   \n",
       "432245      2590.397888            -1.0      15078.916667   \n",
       "432246      2591.604675             1.0      15078.916667   \n",
       "432247      2596.992126             0.0      15073.916667   \n",
       "\n",
       "       DELTA_VFOB_VS_VFOBQTY ALTITUDE_DIFF  VALUE_FOB_MISSING  \n",
       "0                       -2.0        0.0080               55.0  \n",
       "1                       -2.0        0.0029               55.0  \n",
       "2                       -3.0        0.0196               56.0  \n",
       "3                       -2.0        0.4787               56.0  \n",
       "4                       -4.0        0.0083               59.0  \n",
       "...                      ...           ...                ...  \n",
       "432243                  -2.0        1.0000               79.0  \n",
       "432244                  -2.0        0.0000               79.0  \n",
       "432245                  -3.0        2.0000               80.0  \n",
       "432246                  -2.0        2.0000               79.0  \n",
       "432247                  -3.0        1.0000               85.0  \n",
       "\n",
       "[432248 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALUE_FOB_DIFF</th>\n",
       "      <th>leakage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345657</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258947</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110773</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370698</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202174</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105116</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55263</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106896</th>\n",
       "      <td>-4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404380</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VALUE_FOB_DIFF  leakage\n",
       "345657             0.0        2\n",
       "1925               0.0        0\n",
       "258947            -2.0        3\n",
       "110773            -4.0        0\n",
       "370698             2.0        1\n",
       "202174             0.0        0\n",
       "105116            -2.0        0\n",
       "55263             -1.0        0\n",
       "106896            -4.0        0\n",
       "404380            -1.0        1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx = df[[\"VALUE_FOB_DIFF\", \"leakage\"]]\n",
    "dfx.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dfx['VALUE_FOB_DIFF'].plot(kind='hist', edgecolor='black')\n",
    "plt.title('Histogram of VALUE_FOB_DIFF')\n",
    "plt.xlabel('VALUE_FOB_DIFF')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4n/swp60yyd37qg_dmlq1v1_6jw0000gn/T/ipykernel_33096/3209289714.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dfx[\"Label\"] = np.where(dfx['leakage'] == 0, 0, 1)\n"
     ]
    }
   ],
   "source": [
    "dfx[\"Label\"] = np.where(dfx['leakage'] == 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    247436\n",
       "1    184812\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VALUE_FOB_DIFF</th>\n",
       "      <th>leakage</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159819</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356302</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325074</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370173</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204129</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59564</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106005</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73332</th>\n",
       "      <td>-1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        VALUE_FOB_DIFF  leakage  Label\n",
       "159819             1.0        0      0\n",
       "178572             0.0        0      0\n",
       "356302             1.0        2      1\n",
       "325074            -1.0        2      1\n",
       "370173            -2.0        2      1\n",
       "204129            -1.0        0      0\n",
       "59564              0.0        0      0\n",
       "190194             0.0        0      0\n",
       "106005            -2.0        0      0\n",
       "73332             -1.0        0      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfx.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on the training set:\n",
      "Accuracy: 0.5006593444727847\n",
      "Precision: 0.4128793746919231\n",
      "Recall: 0.3963644229924219\n",
      "F1 Score: 0.40445338125178915\n",
      "\n",
      "Performance on the test set:\n",
      "Accuracy: 0.500694042799306\n",
      "Precision: 0.41121918118072837\n",
      "Recall: 0.3943066287108581\n",
      "F1 Score: 0.4025853597774487\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import math\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dfx[['VALUE_FOB_DIFF','leakage']],\n",
    "                                                    dfx['Label'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "#  Calculate the z-scores for the training set\n",
    "mean = X_train['VALUE_FOB_DIFF'].mean()\n",
    "std = X_train['VALUE_FOB_DIFF'].std()\n",
    "X_train['z_score'] = np.abs((X_train['VALUE_FOB_DIFF'] - mean) / std)\n",
    "\n",
    "# Determine the threshold for the z-value\n",
    "threshold = 0.8585858585858586  # Set the threshold value for the z-score\n",
    "\n",
    "# Classify anomalies for the training set based on the threshold\n",
    "X_train['anomaly'] = np.where(X_train['z_score'] > threshold, 1, 0)\n",
    "\n",
    "# Evaluate the performance of the algorithm on the training set\n",
    "y_train_pred = X_train['anomaly']\n",
    "accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "\n",
    "print(\"Performance on the training set:\")\n",
    "print(\"Accuracy:\", accuracy_train)\n",
    "print(\"Precision:\", precision_train)\n",
    "print(\"Recall:\", recall_train)\n",
    "print(\"F1 Score:\", f1_train)\n",
    "\n",
    "# Apply the algorithm to the test set\n",
    "X_test['z_score'] = np.abs((X_test['VALUE_FOB_DIFF'] - mean) / std)\n",
    "X_test['anomaly'] = np.where(X_test['z_score'] > threshold, 1, 0)\n",
    "\n",
    "#  Evaluate the performance on the test set\n",
    "y_test_pred = X_test['anomaly']\n",
    "accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nPerformance on the test set:\")\n",
    "print(\"Accuracy:\", accuracy_test)\n",
    "print(\"Precision:\", precision_test)\n",
    "print(\"Recall:\", recall_test)\n",
    "print(\"F1 Score:\", f1_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.5992283153577396\n",
      "\n",
      "0.050505050505050504\n",
      "1    270065\n",
      "0     75733\n",
      "Name: anomaly, dtype: int64\n",
      "0.5481013990698387\n",
      "\n",
      "0.10101010101010101\n",
      "1    270065\n",
      "0     75733\n",
      "Name: anomaly, dtype: int64\n",
      "0.5481013990698387\n",
      "\n",
      "0.15151515151515152\n",
      "1    270065\n",
      "0     75733\n",
      "Name: anomaly, dtype: int64\n",
      "0.5481013990698387\n",
      "\n",
      "0.20202020202020202\n",
      "1    270065\n",
      "0     75733\n",
      "Name: anomaly, dtype: int64\n",
      "0.5481013990698387\n",
      "\n",
      "0.25252525252525254\n",
      "1    270065\n",
      "0     75733\n",
      "Name: anomaly, dtype: int64\n",
      "0.5481013990698387\n",
      "\n",
      "0.30303030303030304\n",
      "1    270065\n",
      "0     75733\n",
      "Name: anomaly, dtype: int64\n",
      "0.5481013990698387\n",
      "\n",
      "0.35353535353535354\n",
      "1    270065\n",
      "0     75733\n",
      "Name: anomaly, dtype: int64\n",
      "0.5481013990698387\n",
      "\n",
      "0.40404040404040403\n",
      "1    270065\n",
      "0     75733\n",
      "Name: anomaly, dtype: int64\n",
      "0.5481013990698387\n",
      "\n",
      "0.45454545454545453\n",
      "1    208640\n",
      "0    137158\n",
      "Name: anomaly, dtype: int64\n",
      "0.4899780405926516\n",
      "\n",
      "0.5050505050505051\n",
      "0    203788\n",
      "1    142010\n",
      "Name: anomaly, dtype: int64\n",
      "0.40445338125178915\n",
      "\n",
      "0.5555555555555556\n",
      "0    203788\n",
      "1    142010\n",
      "Name: anomaly, dtype: int64\n",
      "0.40445338125178915\n",
      "\n",
      "0.6060606060606061\n",
      "0    203788\n",
      "1    142010\n",
      "Name: anomaly, dtype: int64\n",
      "0.40445338125178915\n",
      "\n",
      "0.6565656565656566\n",
      "0    203788\n",
      "1    142010\n",
      "Name: anomaly, dtype: int64\n",
      "0.40445338125178915\n",
      "\n",
      "0.7070707070707071\n",
      "0    203788\n",
      "1    142010\n",
      "Name: anomaly, dtype: int64\n",
      "0.40445338125178915\n",
      "\n",
      "0.7575757575757576\n",
      "0    203788\n",
      "1    142010\n",
      "Name: anomaly, dtype: int64\n",
      "0.40445338125178915\n",
      "\n",
      "0.8080808080808081\n",
      "0    203788\n",
      "1    142010\n",
      "Name: anomaly, dtype: int64\n",
      "0.40445338125178915\n",
      "\n",
      "0.8585858585858586\n",
      "0    203788\n",
      "1    142010\n",
      "Name: anomaly, dtype: int64\n",
      "0.40445338125178915\n",
      "\n",
      "0.9090909090909091\n",
      "0    274436\n",
      "1     71362\n",
      "Name: anomaly, dtype: int64\n",
      "0.2626123517367492\n",
      "\n",
      "0.9595959595959596\n",
      "0    274436\n",
      "1     71362\n",
      "Name: anomaly, dtype: int64\n",
      "0.2626123517367492\n",
      "\n",
      "1.0101010101010102\n",
      "0    274436\n",
      "1     71362\n",
      "Name: anomaly, dtype: int64\n",
      "0.2626123517367492\n",
      "\n",
      "1.0606060606060606\n",
      "0    274436\n",
      "1     71362\n",
      "Name: anomaly, dtype: int64\n",
      "0.2626123517367492\n",
      "\n",
      "1.1111111111111112\n",
      "0    274436\n",
      "1     71362\n",
      "Name: anomaly, dtype: int64\n",
      "0.2626123517367492\n",
      "\n",
      "1.1616161616161615\n",
      "0    274436\n",
      "1     71362\n",
      "Name: anomaly, dtype: int64\n",
      "0.2626123517367492\n",
      "\n",
      "1.2121212121212122\n",
      "0    274436\n",
      "1     71362\n",
      "Name: anomaly, dtype: int64\n",
      "0.2626123517367492\n",
      "\n",
      "1.2626262626262625\n",
      "0    274436\n",
      "1     71362\n",
      "Name: anomaly, dtype: int64\n",
      "0.2626123517367492\n",
      "\n",
      "1.3131313131313131\n",
      "0    274436\n",
      "1     71362\n",
      "Name: anomaly, dtype: int64\n",
      "0.2626123517367492\n",
      "\n",
      "1.3636363636363635\n",
      "0    307681\n",
      "1     38117\n",
      "Name: anomaly, dtype: int64\n",
      "0.1667347509191374\n",
      "\n",
      "1.4141414141414141\n",
      "0    307681\n",
      "1     38117\n",
      "Name: anomaly, dtype: int64\n",
      "0.1667347509191374\n",
      "\n",
      "1.4646464646464645\n",
      "0    307681\n",
      "1     38117\n",
      "Name: anomaly, dtype: int64\n",
      "0.1667347509191374\n",
      "\n",
      "1.5151515151515151\n",
      "0    307681\n",
      "1     38117\n",
      "Name: anomaly, dtype: int64\n",
      "0.1667347509191374\n",
      "\n",
      "1.5656565656565655\n",
      "0    307681\n",
      "1     38117\n",
      "Name: anomaly, dtype: int64\n",
      "0.1667347509191374\n",
      "\n",
      "1.6161616161616161\n",
      "0    307681\n",
      "1     38117\n",
      "Name: anomaly, dtype: int64\n",
      "0.1667347509191374\n",
      "\n",
      "1.6666666666666667\n",
      "0    307681\n",
      "1     38117\n",
      "Name: anomaly, dtype: int64\n",
      "0.1667347509191374\n",
      "\n",
      "1.7171717171717171\n",
      "0    307681\n",
      "1     38117\n",
      "Name: anomaly, dtype: int64\n",
      "0.1667347509191374\n",
      "\n",
      "1.7676767676767677\n",
      "0    307681\n",
      "1     38117\n",
      "Name: anomaly, dtype: int64\n",
      "0.1667347509191374\n",
      "\n",
      "1.8181818181818181\n",
      "0    325135\n",
      "1     20663\n",
      "Name: anomaly, dtype: int64\n",
      "0.10287680170828638\n",
      "\n",
      "1.8686868686868687\n",
      "0    325135\n",
      "1     20663\n",
      "Name: anomaly, dtype: int64\n",
      "0.10287680170828638\n",
      "\n",
      "1.9191919191919191\n",
      "0    325135\n",
      "1     20663\n",
      "Name: anomaly, dtype: int64\n",
      "0.10287680170828638\n",
      "\n",
      "1.9696969696969697\n",
      "0    325135\n",
      "1     20663\n",
      "Name: anomaly, dtype: int64\n",
      "0.10287680170828638\n",
      "\n",
      "2.0202020202020203\n",
      "0    325135\n",
      "1     20663\n",
      "Name: anomaly, dtype: int64\n",
      "0.10287680170828638\n",
      "\n",
      "2.0707070707070705\n",
      "0    325135\n",
      "1     20663\n",
      "Name: anomaly, dtype: int64\n",
      "0.10287680170828638\n",
      "\n",
      "2.121212121212121\n",
      "0    325135\n",
      "1     20663\n",
      "Name: anomaly, dtype: int64\n",
      "0.10287680170828638\n",
      "\n",
      "2.1717171717171717\n",
      "0    325135\n",
      "1     20663\n",
      "Name: anomaly, dtype: int64\n",
      "0.10287680170828638\n",
      "\n",
      "2.2222222222222223\n",
      "0    325135\n",
      "1     20663\n",
      "Name: anomaly, dtype: int64\n",
      "0.10287680170828638\n",
      "\n",
      "2.2727272727272725\n",
      "0    335094\n",
      "1     10704\n",
      "Name: anomaly, dtype: int64\n",
      "0.0611608071562305\n",
      "\n",
      "2.323232323232323\n",
      "0    335094\n",
      "1     10704\n",
      "Name: anomaly, dtype: int64\n",
      "0.0611608071562305\n",
      "\n",
      "2.3737373737373737\n",
      "0    335094\n",
      "1     10704\n",
      "Name: anomaly, dtype: int64\n",
      "0.0611608071562305\n",
      "\n",
      "2.4242424242424243\n",
      "0    335094\n",
      "1     10704\n",
      "Name: anomaly, dtype: int64\n",
      "0.0611608071562305\n",
      "\n",
      "2.474747474747475\n",
      "0    335094\n",
      "1     10704\n",
      "Name: anomaly, dtype: int64\n",
      "0.0611608071562305\n",
      "\n",
      "2.525252525252525\n",
      "0    335094\n",
      "1     10704\n",
      "Name: anomaly, dtype: int64\n",
      "0.0611608071562305\n",
      "\n",
      "2.5757575757575757\n",
      "0    335094\n",
      "1     10704\n",
      "Name: anomaly, dtype: int64\n",
      "0.0611608071562305\n",
      "\n",
      "2.6262626262626263\n",
      "0    335094\n",
      "1     10704\n",
      "Name: anomaly, dtype: int64\n",
      "0.0611608071562305\n",
      "\n",
      "2.676767676767677\n",
      "0    335094\n",
      "1     10704\n",
      "Name: anomaly, dtype: int64\n",
      "0.0611608071562305\n",
      "\n",
      "2.727272727272727\n",
      "0    341396\n",
      "1      4402\n",
      "Name: anomaly, dtype: int64\n",
      "0.031077470475090106\n",
      "\n",
      "2.7777777777777777\n",
      "0    341396\n",
      "1      4402\n",
      "Name: anomaly, dtype: int64\n",
      "0.031077470475090106\n",
      "\n",
      "2.8282828282828283\n",
      "0    341396\n",
      "1      4402\n",
      "Name: anomaly, dtype: int64\n",
      "0.031077470475090106\n",
      "\n",
      "2.878787878787879\n",
      "0    341396\n",
      "1      4402\n",
      "Name: anomaly, dtype: int64\n",
      "0.031077470475090106\n",
      "\n",
      "2.929292929292929\n",
      "0    341396\n",
      "1      4402\n",
      "Name: anomaly, dtype: int64\n",
      "0.031077470475090106\n",
      "\n",
      "2.9797979797979797\n",
      "0    341396\n",
      "1      4402\n",
      "Name: anomaly, dtype: int64\n",
      "0.031077470475090106\n",
      "\n",
      "3.0303030303030303\n",
      "0    341396\n",
      "1      4402\n",
      "Name: anomaly, dtype: int64\n",
      "0.031077470475090106\n",
      "\n",
      "3.080808080808081\n",
      "0    341396\n",
      "1      4402\n",
      "Name: anomaly, dtype: int64\n",
      "0.031077470475090106\n",
      "\n",
      "3.131313131313131\n",
      "0    341396\n",
      "1      4402\n",
      "Name: anomaly, dtype: int64\n",
      "0.031077470475090106\n",
      "\n",
      "3.1818181818181817\n",
      "0    344558\n",
      "1      1240\n",
      "Name: anomaly, dtype: int64\n",
      "0.008379869542190967\n",
      "\n",
      "3.2323232323232323\n",
      "0    344558\n",
      "1      1240\n",
      "Name: anomaly, dtype: int64\n",
      "0.008379869542190967\n",
      "\n",
      "3.282828282828283\n",
      "0    344558\n",
      "1      1240\n",
      "Name: anomaly, dtype: int64\n",
      "0.008379869542190967\n",
      "\n",
      "3.3333333333333335\n",
      "0    344558\n",
      "1      1240\n",
      "Name: anomaly, dtype: int64\n",
      "0.008379869542190967\n",
      "\n",
      "3.3838383838383836\n",
      "0    344558\n",
      "1      1240\n",
      "Name: anomaly, dtype: int64\n",
      "0.008379869542190967\n",
      "\n",
      "3.4343434343434343\n",
      "0    344558\n",
      "1      1240\n",
      "Name: anomaly, dtype: int64\n",
      "0.008379869542190967\n",
      "\n",
      "3.484848484848485\n",
      "0    344558\n",
      "1      1240\n",
      "Name: anomaly, dtype: int64\n",
      "0.008379869542190967\n",
      "\n",
      "3.5353535353535355\n",
      "0    344558\n",
      "1      1240\n",
      "Name: anomaly, dtype: int64\n",
      "0.008379869542190967\n",
      "\n",
      "3.5858585858585856\n",
      "0    344558\n",
      "1      1240\n",
      "Name: anomaly, dtype: int64\n",
      "0.008379869542190967\n",
      "\n",
      "3.6363636363636362\n",
      "0    345704\n",
      "1        94\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "3.686868686868687\n",
      "0    345704\n",
      "1        94\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "3.7373737373737375\n",
      "0    345704\n",
      "1        94\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "3.7878787878787876\n",
      "0    345704\n",
      "1        94\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "3.8383838383838382\n",
      "0    345704\n",
      "1        94\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "3.888888888888889\n",
      "0    345704\n",
      "1        94\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "3.9393939393939394\n",
      "0    345704\n",
      "1        94\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "3.9898989898989896\n",
      "0    345704\n",
      "1        94\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.040404040404041\n",
      "0    345704\n",
      "1        94\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.090909090909091\n",
      "0    345775\n",
      "1        23\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.141414141414141\n",
      "0    345775\n",
      "1        23\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.191919191919192\n",
      "0    345775\n",
      "1        23\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.242424242424242\n",
      "0    345775\n",
      "1        23\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.292929292929293\n",
      "0    345775\n",
      "1        23\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.343434343434343\n",
      "0    345775\n",
      "1        23\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.393939393939394\n",
      "0    345775\n",
      "1        23\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.444444444444445\n",
      "0    345775\n",
      "1        23\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.494949494949495\n",
      "0    345775\n",
      "1        23\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.545454545454545\n",
      "0    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.595959595959596\n",
      "0    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.646464646464646\n",
      "0    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.696969696969697\n",
      "0    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.747474747474747\n",
      "0    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.797979797979798\n",
      "0    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.848484848484849\n",
      "0    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.898989898989899\n",
      "0    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "4.94949494949495\n",
      "0    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "5.0\n",
      "0    345798\n",
      "Name: anomaly, dtype: int64\n",
      "0.0\n",
      "\n",
      "Best threshold: 0.0\n",
      "Best F1 Score: 0.5992283153577396\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Initialize the best threshold and the best score\n",
    "best_threshold = None\n",
    "best_score = -np.inf\n",
    "\n",
    "# Iterate over a range of possible threshold values\n",
    "for threshold in np.linspace(start=0, stop=5, num=100):\n",
    "    print( threshold)\n",
    "    # Classify anomalies for the training set based on the threshold\n",
    "    X_train['anomaly'] = np.where(X_train['z_score'] > threshold, 1, 0)\n",
    "    y_train_pred = X_train['anomaly']\n",
    "    \n",
    "    print(y_train_pred.value_counts())\n",
    "\n",
    "\n",
    "    # Calculate the score\n",
    "    score = f1_score(y_train, y_train_pred)\n",
    "    print(score)\n",
    "    print()\n",
    "\n",
    "    # If this threshold gives a better score, update the best threshold and the best score\n",
    "    if score > best_score:\n",
    "        best_threshold = threshold\n",
    "        best_score = score\n",
    "\n",
    "print('Best threshold:', best_threshold)\n",
    "print('Best F1 Score:', best_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197871\n",
       "1     49560\n",
       "2     49264\n",
       "3     49103\n",
       "Name: leakage, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.leakage.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"] = np.where(df['leakage'] == 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UTC_TIME</th>\n",
       "      <th>MSN</th>\n",
       "      <th>Flight</th>\n",
       "      <th>FUEL_USED_1</th>\n",
       "      <th>FUEL_USED_2</th>\n",
       "      <th>FUEL_USED_3</th>\n",
       "      <th>FUEL_USED_4</th>\n",
       "      <th>FW_GEO_ALTITUDE</th>\n",
       "      <th>VALUE_FOB</th>\n",
       "      <th>VALUE_FUEL_QTY_CT</th>\n",
       "      <th>...</th>\n",
       "      <th>DATE</th>\n",
       "      <th>TIME</th>\n",
       "      <th>FLIGHT</th>\n",
       "      <th>TOTAL_FUEL_USED</th>\n",
       "      <th>VALUE_FOB_DIFF</th>\n",
       "      <th>TOTAL_FOB_BY_QTY</th>\n",
       "      <th>DELTA_VFOB_VS_VFOBQTY</th>\n",
       "      <th>ALTITUDE_DIFF</th>\n",
       "      <th>VALUE_FOB_MISSING</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-07 07:40:16</td>\n",
       "      <td>A400M-0002</td>\n",
       "      <td>V0926</td>\n",
       "      <td>18.685520</td>\n",
       "      <td>14.602920</td>\n",
       "      <td>11.800570</td>\n",
       "      <td>8.456606</td>\n",
       "      <td>539.7343</td>\n",
       "      <td>17862.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>07:40:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.545616</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>17864.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-07 07:40:17</td>\n",
       "      <td>A400M-0002</td>\n",
       "      <td>V0926</td>\n",
       "      <td>18.790150</td>\n",
       "      <td>14.708280</td>\n",
       "      <td>11.915550</td>\n",
       "      <td>8.561913</td>\n",
       "      <td>539.7372</td>\n",
       "      <td>17862.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>07:40:17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.975893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17864.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-07 07:40:18</td>\n",
       "      <td>A400M-0002</td>\n",
       "      <td>V0926</td>\n",
       "      <td>18.894430</td>\n",
       "      <td>14.812860</td>\n",
       "      <td>12.021070</td>\n",
       "      <td>8.669324</td>\n",
       "      <td>539.7568</td>\n",
       "      <td>17861.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>07:40:18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.397684</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>17864.000000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-07 07:40:19</td>\n",
       "      <td>A400M-0002</td>\n",
       "      <td>V0926</td>\n",
       "      <td>18.999000</td>\n",
       "      <td>14.917660</td>\n",
       "      <td>12.126170</td>\n",
       "      <td>8.777307</td>\n",
       "      <td>539.2781</td>\n",
       "      <td>17861.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>07:40:19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.820137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17863.000000</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.4787</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-07 07:40:20</td>\n",
       "      <td>A400M-0002</td>\n",
       "      <td>V0926</td>\n",
       "      <td>19.103010</td>\n",
       "      <td>15.022960</td>\n",
       "      <td>12.231340</td>\n",
       "      <td>8.885483</td>\n",
       "      <td>539.2698</td>\n",
       "      <td>17858.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2016-10-07</td>\n",
       "      <td>07:40:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.242793</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>17862.000000</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432243</th>\n",
       "      <td>2018-03-21 00:27:12</td>\n",
       "      <td>F-RBAJ</td>\n",
       "      <td>453.0</td>\n",
       "      <td>642.875916</td>\n",
       "      <td>646.364136</td>\n",
       "      <td>652.033813</td>\n",
       "      <td>646.515503</td>\n",
       "      <td>26496.0000</td>\n",
       "      <td>15076.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>00:27:12</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2587.789368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15078.916667</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432244</th>\n",
       "      <td>2018-03-21 00:27:13</td>\n",
       "      <td>F-RBAJ</td>\n",
       "      <td>453.0</td>\n",
       "      <td>643.186523</td>\n",
       "      <td>646.633911</td>\n",
       "      <td>652.346375</td>\n",
       "      <td>646.869507</td>\n",
       "      <td>26496.0000</td>\n",
       "      <td>15076.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>00:27:13</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2589.036316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15078.916667</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432245</th>\n",
       "      <td>2018-03-21 00:27:14</td>\n",
       "      <td>F-RBAJ</td>\n",
       "      <td>453.0</td>\n",
       "      <td>643.535217</td>\n",
       "      <td>646.980530</td>\n",
       "      <td>652.698486</td>\n",
       "      <td>647.183655</td>\n",
       "      <td>26494.0000</td>\n",
       "      <td>15075.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>00:27:14</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2590.397888</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>15078.916667</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432246</th>\n",
       "      <td>2018-03-21 00:27:15</td>\n",
       "      <td>F-RBAJ</td>\n",
       "      <td>453.0</td>\n",
       "      <td>643.844299</td>\n",
       "      <td>647.289856</td>\n",
       "      <td>652.972717</td>\n",
       "      <td>647.497803</td>\n",
       "      <td>26496.0000</td>\n",
       "      <td>15076.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>00:27:15</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2591.604675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15078.916667</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0000</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432247</th>\n",
       "      <td>2018-03-21 00:27:20</td>\n",
       "      <td>F-RBAJ</td>\n",
       "      <td>453.0</td>\n",
       "      <td>645.158203</td>\n",
       "      <td>648.590393</td>\n",
       "      <td>654.374817</td>\n",
       "      <td>648.868713</td>\n",
       "      <td>26496.0000</td>\n",
       "      <td>15070.916667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2018-03-21</td>\n",
       "      <td>00:27:20</td>\n",
       "      <td>980.0</td>\n",
       "      <td>2596.992126</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15073.916667</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>432248 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   UTC_TIME         MSN Flight  FUEL_USED_1  FUEL_USED_2  \\\n",
       "0       2016-10-07 07:40:16  A400M-0002  V0926    18.685520    14.602920   \n",
       "1       2016-10-07 07:40:17  A400M-0002  V0926    18.790150    14.708280   \n",
       "2       2016-10-07 07:40:18  A400M-0002  V0926    18.894430    14.812860   \n",
       "3       2016-10-07 07:40:19  A400M-0002  V0926    18.999000    14.917660   \n",
       "4       2016-10-07 07:40:20  A400M-0002  V0926    19.103010    15.022960   \n",
       "...                     ...         ...    ...          ...          ...   \n",
       "432243  2018-03-21 00:27:12      F-RBAJ  453.0   642.875916   646.364136   \n",
       "432244  2018-03-21 00:27:13      F-RBAJ  453.0   643.186523   646.633911   \n",
       "432245  2018-03-21 00:27:14      F-RBAJ  453.0   643.535217   646.980530   \n",
       "432246  2018-03-21 00:27:15      F-RBAJ  453.0   643.844299   647.289856   \n",
       "432247  2018-03-21 00:27:20      F-RBAJ  453.0   645.158203   648.590393   \n",
       "\n",
       "        FUEL_USED_3  FUEL_USED_4  FW_GEO_ALTITUDE     VALUE_FOB  \\\n",
       "0         11.800570     8.456606         539.7343  17862.000000   \n",
       "1         11.915550     8.561913         539.7372  17862.000000   \n",
       "2         12.021070     8.669324         539.7568  17861.000000   \n",
       "3         12.126170     8.777307         539.2781  17861.000000   \n",
       "4         12.231340     8.885483         539.2698  17858.000000   \n",
       "...             ...          ...              ...           ...   \n",
       "432243   652.033813   646.515503       26496.0000  15076.916667   \n",
       "432244   652.346375   646.869507       26496.0000  15076.916667   \n",
       "432245   652.698486   647.183655       26494.0000  15075.916667   \n",
       "432246   652.972717   647.497803       26496.0000  15076.916667   \n",
       "432247   654.374817   648.868713       26496.0000  15070.916667   \n",
       "\n",
       "        VALUE_FUEL_QTY_CT  ...        DATE      TIME  FLIGHT  TOTAL_FUEL_USED  \\\n",
       "0                     0.0  ...  2016-10-07  07:40:16     0.0        53.545616   \n",
       "1                     0.0  ...  2016-10-07  07:40:17     0.0        53.975893   \n",
       "2                     0.0  ...  2016-10-07  07:40:18     0.0        54.397684   \n",
       "3                     0.0  ...  2016-10-07  07:40:19     0.0        54.820137   \n",
       "4                     0.0  ...  2016-10-07  07:40:20     0.0        55.242793   \n",
       "...                   ...  ...         ...       ...     ...              ...   \n",
       "432243                0.0  ...  2018-03-21  00:27:12   980.0      2587.789368   \n",
       "432244                0.0  ...  2018-03-21  00:27:13   980.0      2589.036316   \n",
       "432245                0.0  ...  2018-03-21  00:27:14   980.0      2590.397888   \n",
       "432246                0.0  ...  2018-03-21  00:27:15   980.0      2591.604675   \n",
       "432247                0.0  ...  2018-03-21  00:27:20   980.0      2596.992126   \n",
       "\n",
       "        VALUE_FOB_DIFF  TOTAL_FOB_BY_QTY  DELTA_VFOB_VS_VFOBQTY ALTITUDE_DIFF  \\\n",
       "0                 -1.0      17864.000000                   -2.0        0.0080   \n",
       "1                  0.0      17864.000000                   -2.0        0.0029   \n",
       "2                 -1.0      17864.000000                   -3.0        0.0196   \n",
       "3                  0.0      17863.000000                   -2.0        0.4787   \n",
       "4                 -3.0      17862.000000                   -4.0        0.0083   \n",
       "...                ...               ...                    ...           ...   \n",
       "432243             0.0      15078.916667                   -2.0        1.0000   \n",
       "432244             0.0      15078.916667                   -2.0        0.0000   \n",
       "432245            -1.0      15078.916667                   -3.0        2.0000   \n",
       "432246             1.0      15078.916667                   -2.0        2.0000   \n",
       "432247             0.0      15073.916667                   -3.0        1.0000   \n",
       "\n",
       "       VALUE_FOB_MISSING  Label  \n",
       "0                   55.0      0  \n",
       "1                   55.0      0  \n",
       "2                   56.0      0  \n",
       "3                   56.0      0  \n",
       "4                   59.0      0  \n",
       "...                  ...    ...  \n",
       "432243              79.0      1  \n",
       "432244              79.0      1  \n",
       "432245              80.0      1  \n",
       "432246              79.0      1  \n",
       "432247              85.0      1  \n",
       "\n",
       "[432248 rows x 27 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177986    0\n",
       "110885    0\n",
       "51043     0\n",
       "113328    0\n",
       "51057     0\n",
       "         ..\n",
       "242459    0\n",
       "326979    1\n",
       "100820    0\n",
       "45155     0\n",
       "53327     0\n",
       "Name: Label, Length: 86450, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:36:28] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training RandomForestClassifier...\n",
      "Training AdaBoostClassifier...\n",
      "Training GradientBoostingClassifier...\n",
      "Training DecisionTreeClassifier...\n",
      "Training LogisticRegression...\n",
      "                        Model       AUC  Accuracy  Precision    Recall  \\\n",
      "0               XGBClassifier  0.880302  0.853036   0.866337  0.869428   \n",
      "1      RandomForestClassifier  0.791772  0.749265   0.744646  0.747997   \n",
      "2          AdaBoostClassifier  0.794961  0.710966   0.704649  0.699536   \n",
      "3  GradientBoostingClassifier  0.840231  0.755628   0.750439  0.748261   \n",
      "4      DecisionTreeClassifier  0.757949  0.764280   0.759202  0.757949   \n",
      "5          LogisticRegression  0.671859  0.657999   0.650748  0.635356   \n",
      "\n",
      "   F1 Score  \n",
      "0  0.853000  \n",
      "1  0.745703  \n",
      "2  0.701228  \n",
      "3  0.749209  \n",
      "4  0.758528  \n",
      "5  0.635670  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the models\n",
    "models = [\n",
    "    XGBClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    DecisionTreeClassifier(),\n",
    "    LogisticRegression(max_iter=1000)\n",
    "]\n",
    "\n",
    "model_names = [\n",
    "    \"XGBClassifier\", \"RandomForestClassifier\", \"AdaBoostClassifier\",\n",
    "    \"GradientBoostingClassifier\", \"DecisionTreeClassifier\",\n",
    "    \"LogisticRegression\"\n",
    "]\n",
    "\n",
    "# Select features and target\n",
    "features = df.select_dtypes(include=[np.number]).drop(\n",
    "    columns=['Label', 'leakage'])\n",
    "target = df['Label']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features,\n",
    "                                                    target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# Prepare an empty DataFrame to store the results\n",
    "results = pd.DataFrame(\n",
    "    columns=['Model', 'AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Iterate over models, train, make predictions and get classification metrics\n",
    "for model, name in zip(models, model_names):\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = report[\"accuracy\"]\n",
    "    precision = report[\"macro avg\"][\"precision\"]\n",
    "    recall = report[\"macro avg\"][\"recall\"]\n",
    "    f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "    results = results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"AUC\": auc,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1\n",
    "        },\n",
    "        ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_0 = test_data[test_data['Label'] == 0]\n",
    "test_data_1 = test_data[test_data['Label'] == 1]\n",
    "\n",
    "# Randomly sample from each dataframe\n",
    "test_data_0 = test_data_0.sample(n=40000, random_state=1)\n",
    "test_data_1 = test_data_1.sample(n=10000, random_state=1)\n",
    "\n",
    "# Concatenate the two samples to get your final sample\n",
    "df_sample_test = pd.concat([test_data_0, test_data_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    40000\n",
       "1    10000\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_test.Label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df_sample_test = df_sample_test.drop('Label', axis=1)\n",
    "y_df_sample_test = df_sample_test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training XGBClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:30:56] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training RandomForestClassifier...\n",
      "Training AdaBoostClassifier...\n",
      "Training GradientBoostingClassifier...\n",
      "Training DecisionTreeClassifier...\n",
      "Training LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.880095</td>\n",
       "      <td>0.80204</td>\n",
       "      <td>0.748302</td>\n",
       "      <td>0.869413</td>\n",
       "      <td>0.762189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.791938</td>\n",
       "      <td>0.75380</td>\n",
       "      <td>0.677325</td>\n",
       "      <td>0.749975</td>\n",
       "      <td>0.689038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.794332</td>\n",
       "      <td>0.74590</td>\n",
       "      <td>0.650781</td>\n",
       "      <td>0.698688</td>\n",
       "      <td>0.662144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838528</td>\n",
       "      <td>0.77616</td>\n",
       "      <td>0.686034</td>\n",
       "      <td>0.744337</td>\n",
       "      <td>0.701690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.759137</td>\n",
       "      <td>0.78334</td>\n",
       "      <td>0.695895</td>\n",
       "      <td>0.759138</td>\n",
       "      <td>0.712714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.667418</td>\n",
       "      <td>0.72502</td>\n",
       "      <td>0.607751</td>\n",
       "      <td>0.631112</td>\n",
       "      <td>0.614649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model       AUC  Accuracy  Precision    Recall  \\\n",
       "0               XGBClassifier  0.880095   0.80204   0.748302  0.869413   \n",
       "1      RandomForestClassifier  0.791938   0.75380   0.677325  0.749975   \n",
       "2          AdaBoostClassifier  0.794332   0.74590   0.650781  0.698688   \n",
       "3  GradientBoostingClassifier  0.838528   0.77616   0.686034  0.744337   \n",
       "4      DecisionTreeClassifier  0.759137   0.78334   0.695895  0.759138   \n",
       "5          LogisticRegression  0.667418   0.72502   0.607751  0.631112   \n",
       "\n",
       "   F1 Score  \n",
       "0  0.762189  \n",
       "1  0.689038  \n",
       "2  0.662144  \n",
       "3  0.701690  \n",
       "4  0.712714  \n",
       "5  0.614649  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############NEW TEST\n",
    "\n",
    "# Prepare an empty DataFrame to store the results\n",
    "results = pd.DataFrame(\n",
    "    columns=['Model','AUC', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
    "\n",
    "# Iterate over models, train, make predictions and get classification metrics\n",
    "for model, name in zip(models, model_names):\n",
    "    print(f\"Training {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_df_sample_test)\n",
    "    y_pred_proba = model.predict_proba(X_df_sample_test)[:, 1]\n",
    "\n",
    "    auc = roc_auc_score(y_df_sample_test, y_pred_proba)\n",
    "    report = classification_report(y_df_sample_test, y_pred, output_dict=True)\n",
    "    accuracy = report[\"accuracy\"]\n",
    "    precision = report[\"macro avg\"][\"precision\"]\n",
    "    recall = report[\"macro avg\"][\"recall\"]\n",
    "    f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "    results = results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"AUC\": auc,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1\n",
    "        },\n",
    "        ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and performing cross-validation on XGBClassifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:51:30] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:52:02] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:52:27] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:52:53] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:53:18] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:53:41] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training and performing cross-validation on RandomForestClassifier...\n",
      "Training and performing cross-validation on AdaBoostClassifier...\n",
      "Training and performing cross-validation on GradientBoostingClassifier...\n",
      "Training and performing cross-validation on DecisionTreeClassifier...\n",
      "Training and performing cross-validation on LogisticRegression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/scottlichtenstein/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV Mean AUC</th>\n",
       "      <th>CV Std AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0.878254</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.853036</td>\n",
       "      <td>0.866337</td>\n",
       "      <td>0.869428</td>\n",
       "      <td>0.853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.805786</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.748942</td>\n",
       "      <td>0.744292</td>\n",
       "      <td>0.747597</td>\n",
       "      <td>0.745346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.794761</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.710966</td>\n",
       "      <td>0.704649</td>\n",
       "      <td>0.699536</td>\n",
       "      <td>0.701228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838821</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.755628</td>\n",
       "      <td>0.750439</td>\n",
       "      <td>0.748261</td>\n",
       "      <td>0.749209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.736967</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.765286</td>\n",
       "      <td>0.760220</td>\n",
       "      <td>0.759084</td>\n",
       "      <td>0.759613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.670906</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.657999</td>\n",
       "      <td>0.650748</td>\n",
       "      <td>0.635356</td>\n",
       "      <td>0.635670</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model  CV Mean AUC  CV Std AUC  Accuracy  Precision  \\\n",
       "0               XGBClassifier     0.878254    0.001295  0.853036   0.866337   \n",
       "1      RandomForestClassifier     0.805786    0.000833  0.748942   0.744292   \n",
       "2          AdaBoostClassifier     0.794761    0.002107  0.710966   0.704649   \n",
       "3  GradientBoostingClassifier     0.838821    0.002915  0.755628   0.750439   \n",
       "4      DecisionTreeClassifier     0.736967    0.001978  0.765286   0.760220   \n",
       "5          LogisticRegression     0.670906    0.001890  0.657999   0.650748   \n",
       "\n",
       "     Recall  F1 Score  \n",
       "0  0.869428  0.853000  \n",
       "1  0.747597  0.745346  \n",
       "2  0.699536  0.701228  \n",
       "3  0.748261  0.749209  \n",
       "4  0.759084  0.759613  \n",
       "5  0.635356  0.635670  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Prepare an empty DataFrame to store the results\n",
    "results = pd.DataFrame(columns=[\n",
    "    'Model', 'CV Mean AUC', 'CV Std AUC', 'Accuracy', 'Precision', 'Recall',\n",
    "    'F1 Score'\n",
    "])\n",
    "\n",
    "# Iterate over models, train, make predictions and get classification metrics\n",
    "for model, name in zip(models, model_names):\n",
    "    print(f\"Training and performing cross-validation on {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Perform cross-validation and get AUC scores\n",
    "    cv_auc = cross_val_score(model, X_train, y_train, cv=5, scoring='roc_auc')\n",
    "\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    accuracy = report[\"accuracy\"]\n",
    "    precision = report[\"macro avg\"][\"precision\"]\n",
    "    recall = report[\"macro avg\"][\"recall\"]\n",
    "    f1 = report[\"macro avg\"][\"f1-score\"]\n",
    "\n",
    "    results = results.append(\n",
    "        {\n",
    "            \"Model\": name,\n",
    "            \"CV Mean AUC\": cv_auc.mean(),\n",
    "            \"CV Std AUC\": cv_auc.std(),\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1\n",
    "        },\n",
    "        ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
